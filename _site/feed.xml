<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://pasana.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://pasana.github.io/" rel="alternate" type="text/html" /><updated>2021-10-03T22:28:37+03:00</updated><id>https://pasana.github.io/feed.xml</id><title type="html">Welcome to Anna Liednikova page</title><subtitle>PhD student developping healthcare chatbot</subtitle><author><name>John Doe</name></author><entry><title type="html">NAACL-2021 takeaways</title><link href="https://pasana.github.io/conference/post_en/2021/06/03/NAACL-2021-papers.html" rel="alternate" type="text/html" title="NAACL-2021 takeaways" /><published>2021-06-03T03:01:21+03:00</published><updated>2021-06-03T03:01:21+03:00</updated><id>https://pasana.github.io/conference/post_en/2021/06/03/NAACL-2021-papers</id><content type="html" xml:base="https://pasana.github.io/conference/post_en/2021/06/03/NAACL-2021-papers.html">&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://pbs.twimg.com/media/E3XewrZXMAQ_ni8.jpg&quot; style=&quot;width: 70%&quot; /&gt; &lt;/p&gt;

&lt;p&gt;After visiting conference NAACL-2021, I would like to share the works that I found intereting in NLP&lt;/p&gt;

&lt;h4&gt; &quot;I'm Not Mad&quot;: Commonsense Implications of Negation and Contradiction &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.346/&quot;&gt;Paper&lt;/a&gt; || &lt;a href=&quot;https://underline.io/events/122/posters/4246/poster/20639-'i'm-not-mad'-commonsense-implications-of-negation-and-contradiction&quot;&gt;Poster&lt;/a&gt; || &lt;a href=&quot;&quot;&gt;Video&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Negation is one of the most common problems in the NLP tasks. Liwei Jiang, Antoine Bosselut, Chandra Bhagavatula and Yejin Choi presented a new step forward - &lt;a href=&quot;https://github.com/liweijiang/anion&quot;&gt;ANION&lt;/a&gt;,  a  new  com-monsense knowledge graph with 624K if-then rules  focusing  on  negated  and  contradictory events. They compare the result of this model with ATOMIC. Both knowledge-graph created manually by populating social  commonsense knowledge about event pre-conditions, event post-conditions,  and  static  attributes  in  the  form  of natural languageif-then rules. Drawback of ATOMIC that it doesn’t contains a lot of negatives samples (only 2.1%). The table below shows the main rules used by the authors.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;anion_examples.png&quot; /&gt; &lt;/p&gt;

&lt;p&gt;I am curious to see how using this knowledge graph can help improve performance of NLI models and if it could be used for improving datasets quality by reducing contradiction inside them.&lt;/p&gt;

&lt;h4&gt; TuringAdvice: A Generative and Dynamic Evaluation of Language Use &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.386.pdf&quot;&gt;Paper&lt;/a&gt; || &lt;a href=&quot;https://underline.io/events/122/posters/4131/poster/21118-turingadvice-a-generative-and-dynamic-evaluation-of-language-use&quot;&gt;Poster&lt;/a&gt; || &lt;a href=&quot;&quot;&gt;Video&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Another promising dataset is &lt;a href=&quot;https://github.com/rowanz/turingadvice&quot;&gt;TuringAdvice&lt;/a&gt; created and relased by Rowan Zellers, Yejin Choi, Elizabeth Clark, Ali Farhadi, Ari Holtzman, Lianhui Qin. TuringAdvice is a challenge for AI systems, to test their understanding of natural language. The key idea is that must generate advice in response to someone who is seeking it. To pass the challenge, the machine’s advice must be at least as helpful as human-written advice for that situation.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://camo.githubusercontent.com/f18476b33bc7036a607944820e44a91822fce4cce7a7f3a657c8ed97575665c4/68747470733a2f2f692e696d6775722e636f6d2f6549546d4f366f2e706e67&quot; style=&quot;width:50%&quot; /&gt; &lt;/p&gt;

&lt;p&gt;I believe that giving a proper advice could be the next important compontent of the dialogue systems as well as empathy. Looking forward to the follo-up work!&lt;/p&gt;

&lt;h4&gt; mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.41/&quot;&gt;Paper&lt;/a&gt; || &lt;a href=&quot;https://underline.io/events/122/posters/4132/poster/20825-mt5-a-massively-multilingual-pre-trained-text-to-text-transformer&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In this paper, a Google team introduced mT5, a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. There are 5 sizes availble: small, Base, Large, XL, XXL. You can find them all at &lt;a href=&quot;https://goo.gle/mt5-code&quot;&gt;official repository&lt;/a&gt; or test right away on &lt;a href=&quot;https://huggingface.co/models?search=google%2Fmt5&quot;&gt;Hugging Face platform&lt;/a&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://miro.medium.com/max/4006/1*D0J1gNQf8vrrUpKeyD8wPA.png&quot; style=&quot;width:50%&quot; /&gt; &lt;/p&gt;

&lt;p&gt;As a reminder: T5 is Text-to-Text generation model, that was tranied on plently of NLP tasks at once, so that you can use the same ‘black-box’ with a short idenifier of the task in the beginning of input to control the format of the output.&lt;/p&gt;

&lt;h4&gt; {ConVEx}: Data-Efficient and Few-Shot Slot Labeling &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.264/&quot;&gt;Paper&lt;/a&gt; || &lt;a href=&quot;https://underline.io/events/122/posters/4692/poster/20548-convex-data-efficient-and-few-shot-slot-labeling&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Matthew Henderson and Ivan Vulić presented ConVEx (Conversational Value Extractor), an efficient pretraining and fine-tuning neural approach for slot-labeling dialog tasks. I was glad to see this work, since it seems to me to be one of follow-up works of &lt;a href=&quot;https://arxiv.org/pdf/1911.03688&quot;&gt;ConveRT&lt;/a&gt; embeddings, which are very fast and precise for dialogue response retrieval.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://www.polyai.com/wp-content/uploads/2020/10/Screenshot-2020-10-22-at-14.49.36.png&quot; style=&quot;width: 50%&quot; /&gt; &lt;/p&gt;

&lt;h4&gt; On learning and representing social meaning in NLP: a sociolinguistic perspective &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.50/&quot;&gt;Paper&lt;/a&gt; || &lt;a href=&quot;https://underline.io/events/122/posters/4134/poster/20840-on-learning-and-representing-social-meaning-in-nlp-a-sociolinguistic-perspective&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Dong Nguyen presenting this position paper in collaboration with Jack Grieve and Laura Rosseel. This work immediately caught my attention since I saw &lt;a href=&quot;https://www.aclweb.org/anthology/2020.coling-main.75.pdf&quot;&gt;previous work on COLING 2020&lt;/a&gt;.&lt;/p&gt;

&lt;table&gt; 
&lt;td width=&quot;50%&quot; align=&quot;center&quot;&gt; &lt;img src=&quot;https://d3i71xaburhd42.cloudfront.net/1012ee9d7f33dfed330f9dd8030decc0bea17c12/2-Figure1-1.png&quot; style=&quot;width: 100%&quot; /&gt; &lt;/td&gt;
&lt;td width=&quot;50%&quot; align=&quot;center&quot;&gt; &lt;img src=&quot;https://d3i71xaburhd42.cloudfront.net/1012ee9d7f33dfed330f9dd8030decc0bea17c12/5-Table3-1.png&quot; style=&quot;width: 100%&quot; /&gt; &lt;/td&gt;
&lt;/table&gt;

&lt;p&gt;They way we speak can tell a lot about us and our relation with our interlocor, it’s changes over time and with different generations and events. It could be very interesting to use this information not only for analysis, but also for controlable utterance generation.&lt;/p&gt;

&lt;h4&gt; The Importance of Modeling Social Factors of Language: Theory and Practice &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.49/&quot;&gt;Paper&lt;/a&gt; || &lt;a href=&quot;https://underline.io/events/122/posters/4134/poster/20841-the-importance-of-modeling-social-factors-of-language-theory-and-practice&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Dirk Hovy and Diyi Yang&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://pbs.twimg.com/media/E3RUCzaXEAAdfUb.jpg&quot; style=&quot;width: 30%&quot; /&gt; &lt;/p&gt;

&lt;h4&gt; Human-like informative conversations: Better acknowledgements using conditional mutual information &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.61/&quot;&gt;Paper&lt;/a&gt; || &lt;a href=&quot;https://underline.io/events/122/posters/4143/poster/20851-human-like-informative-conversations-better-acknowledgements-using-conditional-mutual-information&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ashwin Paranjape, Christopher Manning&lt;/p&gt;

&lt;h4&gt; Beyond Black &amp;amp; White: Leveraging Annotator Disagreement via Soft-Label Multi-Task Learning &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.204/&quot;&gt;Paper&lt;/a&gt; || &lt;a href=&quot;https://underline.io/events/122/posters/4195/poster/21014-beyond-black-and-white-leveraging-annotator-disagreement-via-soft-label-multi-task-learning&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Tommaso Fornaciari presented his joing work with Dirk Hovy, Silviu Paun, Barbara Plank, Massimo Poesio, Alexandra Uma about the importance of stepping back from “black and white” labels, but instead of that to look at their distribution.&lt;/p&gt;

&lt;h4&gt; Explainable Multi-hop Verbal Reasoning Through Internal Monologue &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.97/&quot;&gt;Paper&lt;/a&gt; || &lt;a href=&quot;https://underline.io/events/122/posters/4155/poster/20896-explainable-multi-hop-verbal-reasoning-through-internal-monologue&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Zhengzhong Liang, Steven Bethard, Mihai Surdeanu&lt;/p&gt;

&lt;h4&gt; Negative language transfer in learner English: A new dataset &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.251/&quot;&gt;Paper&lt;/a&gt; || &lt;a href=&quot;https://underline.io/events/122/posters/4215/poster/21068-negative-language-transfer-in-learner-english-a-new-dataset&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Another interesting work is detecting language transfer in English presented by Leticia Farias Wanderley, Carrie Demmans Epp, Nicole (Zixin) Zhao.&lt;/p&gt;

&lt;p&gt;That’s true that learning a new language, we tend to transfer our knowledge from other languages to a new one. On the one hand it could help to detect your original language, on the other hand revealing such patterns could help the learners to develop faster and in more effient way. Automatic personalized corrective feedback can help language learners from different backgrounds better acquire a new language.&lt;/p&gt;

&lt;h4&gt; Open-Domain Question Answering Goes Conversational via Question Rewriting &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://underline.io/events/122/posters/4133/poster/20835-open-domain-question-answering-goes-conversational-via-question-rewriting&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Raviteja Anantha, Svitlana Vakulenko, Srinivas Chappidi, Shayne Longpre, Stephen Pulman, Zhucheng Tu&lt;/p&gt;

&lt;p&gt;Shared task on SCAI QReCC: https://scai.info/scai-qrecc/&lt;/p&gt;

&lt;h4&gt; Is Incoherence Surprising? Targeted Evaluation of Coherence Prediction from Language Models &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.328/&quot;&gt;Paper&lt;/a&gt; || &lt;a href=&quot;https://underline.io/events/122/posters/4243/poster/20618-is-incoherence-surprisingquestion-targeted-evaluation-of-coherence-prediction-from-language-models&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Anne Beyer has presented her work with Sharid Loáiciga, David Schlangen about capacity of the models&lt;/p&gt;

&lt;p&gt;It remind me about FED framework for dialogue evaluation. The work seems to be very interesting and enough useful for few-turns dialogues, but doesn’t giving the expected feedback for long dialogues since they are already pretty unique, so the perplexety is pretty low.&lt;/p&gt;

&lt;h4&gt; Preregistering NLP research &lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.51/&quot;&gt;Paper&lt;/a&gt; || &lt;a href=&quot;https://underline.io/events/122/posters/4134/poster/20842-preregistering-nlp-research&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Emiel van Miltenburg, Emiel Krahmer, Chris van der Lee&lt;/p&gt;</content><author><name>Anna Liednikova</name></author><category term="post_en" /><category term="conference" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pbs.twimg.com/media/E3XewrZXMAQ_ni8.jpg" /><media:content medium="image" url="https://pbs.twimg.com/media/E3XewrZXMAQ_ni8.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">double critic of chatbot</title><link href="https://pasana.github.io/chatbot/post_en/2020/11/23/double-critic-of-chatbot.html" rel="alternate" type="text/html" title="double critic of chatbot" /><published>2020-11-23T02:01:21+02:00</published><updated>2020-11-23T02:01:21+02:00</updated><id>https://pasana.github.io/chatbot/post_en/2020/11/23/double-critic-of-chatbot</id><content type="html" xml:base="https://pasana.github.io/chatbot/post_en/2020/11/23/double-critic-of-chatbot.html">&lt;p&gt;To train a good quality chatbot from scratch usually requires either a lot of data or a very limited context. After all, its developers are interested in the successful completion of tasks by the chatbot, but are rarely interested in a detailed description of the context, where all possible situations will be considered and provided for. It is more efficient to develop a chatbot that will slowly figure it out in the proposed context.&lt;/p&gt;

&lt;p&gt;Behind most of the interesting chatbots are Reinforcement learning algorithms that have their origins in behavioral biology. Very roughly and simply, they can be summarized as follows: there are short-term rewards, and there are long-term ones, and the model learns to identify strategies that balance between these rewards. This kind of training for a long-term goal.&lt;/p&gt;

&lt;p&gt;You can talk a lot and for a long time on this topic, but today I would like to dwell on only one concept: Actor-Critic.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/actor-critic.png&quot; alt=&quot;Actor - Critic&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The point is to split the model into two parts: one to calculate the actions based on the state, and the other to get the values of the effectiveness of that action. As an example, the boy-mom relationship from &lt;a href=&quot;https://theaisummer.com/Actor_critics/&quot;&gt;this great article&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The child (actor) constantly tries new things and exploring the environment around him. He eats its own toys, he touches the hot oven, he bangs his head in the wall (I mean why not). His mother (the critic) watches him and either criticize or compliment him. The child listen to what his mother told him and adjust his behavior. As the kid grows, he learns what actions are bad or good and he essentially learns to play the game called life.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The executor takes the state as input and outputs the best action. In essence, he controls the behavior of the agent by studying the optimal policy. The critic, on the other hand, evaluates action by calculating a value function (based on the existing value system). These two models participate in a game where over time they both get better in their role. As a result, the overall architecture will learn to play the game more efficiently than the two methods alone.&lt;/p&gt;

&lt;p&gt;The motivation for writing this post was the new article &lt;a href=&quot;https://www.aclweb.org/anthology/2020.findings-emnlp.75/&quot;&gt;Actor-Double-Critic: Incorporating Model-Based Critic for Task-Oriented Dialogue Systems&lt;/a&gt;. In it, the authors showed that to improve the dialogue, you need to use not one critic, but two! One makes his judgment about his knowledge of the system (model-based), and the other - based on the environment and perspectives (model-free). Such is the view from the past and the view from the future.&lt;/p&gt;

&lt;p&gt;The creation of such a model helped them increase the success of the chatbot for reserving a table in a restaurant up to 80%. At the end of the article there is an example of a dialogue before and after, which I invite you to familiarize yourself with.&lt;/p&gt;

&lt;p&gt;How often do you weigh decisions with your inner critic? On the basis of what information do you draw conclusions about the effectiveness of your actions? Based on existing experience? Or desired perspectives? How independent are these judgments?&lt;/p&gt;</content><author><name>Anna Liednikova</name></author><category term="post_en" /><category term="chatbot" /><summary type="html">To train a good quality chatbot from scratch usually requires either a lot of data or a very limited context. After all, its developers are interested in the successful completion of tasks by the chatbot, but are rarely interested in a detailed description of the context, where all possible situations will be considered and provided for. It is more efficient to develop a chatbot that will slowly figure it out in the proposed context.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pasana.github.io/assets/img/posts/actor-critic.png" /><media:content medium="image" url="https://pasana.github.io/assets/img/posts/actor-critic.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">двойной внутренний критик чатбота</title><link href="https://pasana.github.io/%D1%87%D0%B0%D1%82%D0%B1%D0%BE%D1%82/post_ru/2020/11/23/dvojnoj-vnutrennij-kritik-chatbota.html" rel="alternate" type="text/html" title="двойной внутренний критик чатбота" /><published>2020-11-23T02:01:21+02:00</published><updated>2020-11-23T02:01:21+02:00</updated><id>https://pasana.github.io/%D1%87%D0%B0%D1%82%D0%B1%D0%BE%D1%82/post_ru/2020/11/23/dvojnoj-vnutrennij-kritik-chatbota</id><content type="html" xml:base="https://pasana.github.io/%D1%87%D0%B0%D1%82%D0%B1%D0%BE%D1%82/post_ru/2020/11/23/dvojnoj-vnutrennij-kritik-chatbota.html">&lt;p&gt;Чтобы с нуля обучить чатбота хорошего качества, как правило, нужно либо много данных, либо очень ограниченный контекст. Ведь его разработчики заинтересованны в успешном выполнении задач чатботом, но редко заинтересованы в детальном описании контекста, где все возможные ситуации будут рассмотрены и предусмотрены. Более эффективным является разработка такого чатбота, который потихоньку и сам разберется в предложенном контексте.&lt;/p&gt;

&lt;p&gt;За большинством интересных чатботов скрывается алгоритмы подкрепления (Reinforcement learning), которые имеют свое начало в поведенческой биологии. Очень грубо и просто их можно свести к следующему: есть краткосрочные вознаграждения, а есть долгосрочные, а модель учится определять стратегии, которые балансируют между этими вознаграждениями. Такая своего рода дрессировка на долгосрочную цель.&lt;/p&gt;

&lt;p&gt;Говорить на эту тему можно много и долго, но сегодня я бы хотела остановиться только на одной концепции: Исполнитель-Критик (Actor-Critic).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/actor-critic.png&quot; alt=&quot;Actor - Critic&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Суть в том, чтобы разделить модель на две части: одну для вычисления действий на основе состояния, а другую - для получения значений результативности этого  действия. Как пример, отношения мальчик-мама из &lt;a href=&quot;https://theaisummer.com/Actor_critics/&quot;&gt;этой замечательной статьи&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Ребенок (исполнитель) постоянно пробует новое и исследует окружающую его среду. Он ест свои игрушки, прикасается к раскаленной духовке, бьется головой об стену (почему бы и нет?). Его мать (критик) наблюдает за ним и либо критикует, либо делает комплименты. Ребенок слушает, что ему говорит мать, и корректирует свое поведение. По мере того, как ребенок растет, он узнает, какие действия являются плохими или хорошими, и, по сути, учится играть в игру, называемую жизнью.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Исполнитель принимает на вход состояние и выводит наилучшее действие. По сути, он контролирует поведение агента, изучая оптимальную политику. Критик, с другой стороны, оценивает действие, вычисляя функцию ценности (на основе существующей системе ценностей). Эти две модели участвуют в игре, где со временем они обе становятся лучше в своей роли. В результате общая архитектура научится играть в игру более эффективно, чем два метода по отдельности.&lt;/p&gt;

&lt;p&gt;Мотивацией к написанию данного поста послужила новая статья &lt;a href=&quot;https://www.aclweb.org/anthology/2020.findings-emnlp.75/&quot;&gt;Actor-Double-Critic: Incorporating Model-Based Critic for Task-Oriented Dialogue Systems&lt;/a&gt;. В ней авторы показали, что для улучшения диалога, нужно использовать не одного критика, а целых двоих! Один выдвигает свое суждение относительно своих знаний о системе (model-based), а другой - на основе окружения и перспектив (model-free). Такой вот взгляд из прошлого и взгляд из будущего.&lt;/p&gt;

&lt;p&gt;Создание такой модели помогло им увеличить успешность чатбота по заказыванию столика в ресторане до 80%. В конце статьи находится пример диалога до и после, с которым я предлагаю вам ознакомится.&lt;/p&gt;

&lt;p&gt;А вы как часто взвешиваете решения со своим внутренним критиком? На основе какой информации делаете выводы о результативности ваших действий? На основе существующего опыта? Или желаемых перспектив? Насколько независимы эти суждения?&lt;/p&gt;</content><author><name>Anna Liednikova</name></author><category term="post_ru" /><category term="чатбот" /><summary type="html">Чтобы с нуля обучить чатбота хорошего качества, как правило, нужно либо много данных, либо очень ограниченный контекст. Ведь его разработчики заинтересованны в успешном выполнении задач чатботом, но редко заинтересованы в детальном описании контекста, где все возможные ситуации будут рассмотрены и предусмотрены. Более эффективным является разработка такого чатбота, который потихоньку и сам разберется в предложенном контексте.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pasana.github.io/assets/img/posts/actor-critic.png" /><media:content medium="image" url="https://pasana.github.io/assets/img/posts/actor-critic.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">chatbot and role models</title><link href="https://pasana.github.io/chatbot/post_en/2020/11/18/chatbot-and-role-models.html" rel="alternate" type="text/html" title="chatbot and role models" /><published>2020-11-18T02:01:21+02:00</published><updated>2020-11-18T02:01:21+02:00</updated><id>https://pasana.github.io/chatbot/post_en/2020/11/18/chatbot-and-role-models</id><content type="html" xml:base="https://pasana.github.io/chatbot/post_en/2020/11/18/chatbot-and-role-models.html">&lt;p&gt;Our interactions are driven by the social context. In most cases, being in society, we perform some kind of social role, and sometimes several. Since the context of using a particular chatbot, as a rule, remains unchanged, it can be assumed that it also has one role model. But is it?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/roles.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This has been true for a long time. In general, chatbots can be divided into two main camps: goal-oriented (there is a task, it needs to be solved: order tickets, a hotel, make a diagnosis) and chit-chat (talk about everything and nothing, as long as there is enough resource).&lt;/p&gt;

&lt;p&gt;And only in 2017, Zhou Yu, Alan Black and Alexander Rudnitsky presented the first hybrid (&lt;a href=&quot;https://www.ijcai.org/Proceedings/2017/0589.pdf&quot;&gt;Learning conversational systems that interleave task and non-task content&lt;/a&gt;). Through their research, they have shown that a system that alternates between social content (chit chat) and task content (goal-oriented) is more successful at accomplishing a task and more attractive than a purely task-oriented (performer).&lt;/p&gt;

&lt;p&gt;The main task of the chatbot they presented was to recommend films, but in order for it to cope with the task more efficiently, several communication strategies (from the role of a chit-chat) were added to the main set of functions (the role of the goal-oriented bot):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt; &lt;b&gt; Active listening strategies &lt;/b&gt; engage users by actively participating in the conversation, such as asking additional questions about the current topic &lt;/li&gt;
&lt;li&gt; &lt;b&gt; Rationale strategies &lt;/b&gt; using knowledge from the knowledge base, linking and proposing facts for the current topic &lt;/li&gt;
&lt;li&gt; &lt;b&gt; Personalized strategies &lt;/b&gt; - adaptation to the user using automatically extracted information from a conversation with him. For example, offer to talk more about a specific topic, knowing that the user has previously been involved in that topic. &lt;/li&gt;
  &lt;/ul&gt;

&lt;p&gt;But in general, the development of performers and talkers individually developed faster than together. Nevertheless, the tendency to combine various roles behind the interface of a single system remained.&lt;/p&gt;

&lt;p&gt;For example, at the end of the same year, the Heriot-Watt University team put forward the social dialogue system [Alana] (https://arxiv.org/abs/1712.07558) (chatterbox) as part of the &lt;a href=&quot;https://developer.amazon .com / alexaprize&quot;&gt;Alexa Prize&lt;/a&gt;. This system combined several roles at once, which are highlighted in gray in the next fragment of the dialogue.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/alana.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And in October 2020, the first [article] was published (https://dl.acm.org/doi/10.1145/3383652.3423889), which showed that mixing roles did not give positive results. It turns out that the public space and work environment create a completely different context than when you are at home talking face to face with your virtual assistant like Alexa.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/busy.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And Facebook released a chatbot &lt;a href=&quot;https://ai.facebook.com/blog/state-of-the-art-open-source-chatbot/&quot;&gt;Blender&lt;/a&gt;, which combines the following communication functions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt; Engaging use of personality (&lt;a href=&quot;https://arxiv.org/abs/1801.07243&quot;&gt;PersonaChat&lt;/a&gt;) &lt;/li&gt;
&lt;li&gt; Engaging use of knowledge (&lt;a href=&quot;https://arxiv.org/abs/1811.01241&quot;&gt;Wizard of Wikipedia&lt;/a&gt;) &lt;/li&gt;
&lt;li&gt; Display of empathy (&lt;a href=&quot;https://arxiv.org/abs/1811.00207&quot;&gt;Empathetic Dialogues&lt;/a&gt;) &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Although … Hmm … Wait, doesn’t this remind you of all those chatbot’s communication strategies for recommending movies? Yeah, everything is the same, only now the methods are more effective. If earlier it was a limited set of templates, now each strategy is a previously developed chatbot that generates text, being trained on a huge amount of data.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/blender.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see, the idea of combining various roles and communication strategies is far from new, but it is still very relevant from three sides: 1) development of each role separately, 2) determination of the optimal set of roles for the task, 3) determination of the optimal criterion for selecting a candidate for output to the user.&lt;/p&gt;

&lt;p&gt;And you, dear friends, how many roles do you have in your arsenal and how often do you use them? Do you feel that sometimes it’s time to pump up a joker, empath, or arrogant person? How many roles do you allow yourself to mix up in your workplace? And in general, did everyone think about it before?&lt;/p&gt;</content><author><name>Anna Liednikova</name></author><category term="post_en" /><category term="chatbot" /><summary type="html">Our interactions are driven by the social context. In most cases, being in society, we perform some kind of social role, and sometimes several. Since the context of using a particular chatbot, as a rule, remains unchanged, it can be assumed that it also has one role model. But is it?</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pasana.github.io/assets/img/posts/roles.png" /><media:content medium="image" url="https://pasana.github.io/assets/img/posts/roles.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">чатботы и ролевые модели</title><link href="https://pasana.github.io/%D1%87%D0%B0%D1%82%D0%B1%D0%BE%D1%82/post_ru/2020/11/18/chatboty-i-rolevye-modeli.html" rel="alternate" type="text/html" title="чатботы и ролевые модели" /><published>2020-11-18T02:01:21+02:00</published><updated>2020-11-18T02:01:21+02:00</updated><id>https://pasana.github.io/%D1%87%D0%B0%D1%82%D0%B1%D0%BE%D1%82/post_ru/2020/11/18/chatboty-i-rolevye-modeli</id><content type="html" xml:base="https://pasana.github.io/%D1%87%D0%B0%D1%82%D0%B1%D0%BE%D1%82/post_ru/2020/11/18/chatboty-i-rolevye-modeli.html">&lt;p&gt;Наше взаимодействие обусловлено социальным контекстом. В большинстве случаев, находясь в обществе мы выполняем какую-то социальную роль, а иногда несколько. Поскольку контекст использования определенного чатбота, как правило, остается неизменным, то и можно предположить, что и ролевая модель у него одна. Но так ли это?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/roles.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Это было действительно так на протяжении долгого времени. В целом,  чатботов можно разделить на два основных лагеря: исполнители (есть задача, ее нужно решить: заказать билеты, гостиницу, поставить диагноз) и болтуны (поговорить обо всем и ни о чем, пока хватает ресурса).&lt;/p&gt;

&lt;p&gt;И лишь в 2017 году Zhou Yu, Alan Black и Александр Рудницкий представили первого гибрида (&lt;a href=&quot;https://www.ijcai.org/Proceedings/2017/0589.pdf&quot;&gt;Learning conversational systems that interleave task and non-task content&lt;/a&gt;). Своим исследованием, они показали, что система, которая чередует социальный контент (болтуна) и содержание задачи (исполнителя), более успешна в выполнения задачи и более привлекательная по сравнению с чисто ориентированной на задачи (исполнителем).&lt;/p&gt;

&lt;p&gt;Основной задачей представленного ими чатбота была рекомендация фильмов, но чтобы он справлялся с задачей более эффективно, к основному набору функций (роли исполнителя) добавили несколько коммуникативных стратегий (из роли болтуна):&lt;/p&gt;

&lt;ul&gt;
    &lt;li&gt;&lt;b&gt; Стратегии активного слушания &lt;/b&gt; вовлекают пользователей, активно участвуя в беседе, например задавая дополнительные вопросы по текущей теме&lt;/li&gt;
    &lt;li&gt;&lt;b&gt;Стратегии обоснования &lt;/b&gt; с использованием информации из базы знаний, связывание и предложение фактов для текущей темы&lt;/li&gt;
    &lt;li&gt;&lt;b&gt;Персонализированные стратегии &lt;/b&gt; - адаптация к пользователю, используя автоматически извлеченную информацию из разговора с ним. Например, предложить поговорить больше на определенную тему, зная, что пользователь ранее был вовлечен в эту тему.&lt;/li&gt;
  &lt;/ul&gt;

&lt;p&gt;Но в целом развитие исполнителей и болтунов по отдельности развивалось быстрее нежели вместе. Тем не менее тенденция объединять различные роли  за интерфейсом единой системы осталась.&lt;/p&gt;

&lt;p&gt;Например, в конце того же года команда Heriot-Watt University выдвинули социальную диалоговую систему &lt;a href=&quot;https://arxiv.org/abs/1712.07558&quot;&gt;Alana&lt;/a&gt; (болтун) в рамках соревнования &lt;a href=&quot;https://developer.amazon.com/alexaprize&quot;&gt;Alexa Prize&lt;/a&gt;. Эта система объединяла в себе сразу несколько ролей, которые серым цветом выделены в следующем фрагменте диалога.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/alana.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;А в октябре 2020 года вышла первая &lt;a href=&quot;https://dl.acm.org/doi/10.1145/3383652.3423889&quot;&gt;статья&lt;/a&gt;, которая показала, что смешивание ролей не дало положительных результатов. Оказывается, что публичное место и рабочая атмосфера создают совершенно иной контекст, нежели когда вы дома тет-а-тет говорите со своим виртуальным помощником на подобии Alexa.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/busy.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;А Facebook выпустил чатбота &lt;a href=&quot;https://ai.facebook.com/blog/state-of-the-art-open-source-chatbot/&quot;&gt;Blender&lt;/a&gt;, который объединил в себе следующие коммуникативные функции:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt; Увлечение с использованием знаний о личности (&lt;a href=&quot;https://arxiv.org/abs/1801.07243&quot;&gt;PersonaChat&lt;/a&gt;) &lt;/li&gt;
&lt;li&gt; Увлечение с помощью использования знаний (&lt;a href=&quot;https://arxiv.org/abs/1811.01241&quot;&gt;Wizard of Wikipedia&lt;/a&gt;) &lt;/li&gt;
&lt;li&gt; Проявление сочувствия (&lt;a href=&quot;https://arxiv.org/abs/1811.00207&quot;&gt;Empathetic Dialogues&lt;/a&gt;) &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Хотя… Хм… Подождите, а не напоминает ли это все те самые коммуникативные стратегии чатбота по рекомендации фильмов? Ага, все то же самое, только теперь методы более эффективные. Если раньше это был ограниченный набор шаблонов, то теперь каждая стратегия - это ранее разработанный чатбот, который генерирует текст, будучи натренированным на огромном количестве данных.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/blender.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Как видите, идея объединения различных ролей и коммуникативных стратегий далеко не нова, но до сих очень актуальна с трех сторон: 1) развитие каждой роли отдельно, 2) определение оптимального набора ролей для выполнения задачи, 3) определение оптимального критерия выбора кандидата для вывода пользователю.&lt;/p&gt;

&lt;p&gt;А вы, дорогие друзья, как много ролей имеете в своем арсенале и как часто ими пользуетесь? Чувствуете, что порою пора прокачать шутника, эмпата или зазнайку? Как много ролей позволяете себе смешивать себе на рабочем месте? Да и вообще задумывались ли об этом всем ранее?&lt;/p&gt;</content><author><name>Anna Liednikova</name></author><category term="post_ru" /><category term="чатбот" /><summary type="html">Наше взаимодействие обусловлено социальным контекстом. В большинстве случаев, находясь в обществе мы выполняем какую-то социальную роль, а иногда несколько. Поскольку контекст использования определенного чатбота, как правило, остается неизменным, то и можно предположить, что и ролевая модель у него одна. Но так ли это?</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pasana.github.io/assets/img/posts/roles.png" /><media:content medium="image" url="https://pasana.github.io/assets/img/posts/roles.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">common sense and chatbot</title><link href="https://pasana.github.io/chatbot/post_en/2020/11/14/common-sense-and-chatbot.html" rel="alternate" type="text/html" title="common sense and chatbot" /><published>2020-11-14T02:01:21+02:00</published><updated>2020-11-14T02:01:21+02:00</updated><id>https://pasana.github.io/chatbot/post_en/2020/11/14/common-sense-and-chatbot</id><content type="html" xml:base="https://pasana.github.io/chatbot/post_en/2020/11/14/common-sense-and-chatbot.html">&lt;p&gt;It is pleasant to maintain a conversation with a person with common sense: he is able to think logically, has a basic set of facts about the world around him, and can connect them in a sequence. As a rule, we are not aware of all this and draw conclusions intuitively. But in order to teach a virtual friend common sense, you need to decompose the process into components. What are they in general terms?&lt;/p&gt;

&lt;p&gt;Most of today’s chatbots are semantic. I am not counting those who are built on deterministic rules. The “train of thought” of the semantic chatbot can be correlated with our intuitive thinking, built on associations.&lt;/p&gt;

&lt;p&gt;The ability to reason is a more energy-intensive skill and includes building not so much associative connections as causal ones.&lt;/p&gt;

&lt;p&gt;As an example, I will give a slide from &lt;a href=&quot;https://homes.cs.washington.edu/~msap/acl2020-commonsense/slides/03%20-%20Commonsense%20Resources.pdf&quot;&gt;Commonsense Tutorial (T6), Commonsense resources&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/t6-slide1.jpg&quot; style=&quot;width: 50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To be able to build these causal relationships requires some basic set of facts, axioms of sorts, about the environment.&lt;/p&gt;

&lt;p&gt;And here we smoothly come to the concept of a knowledge base and reflections. But it is only recently that they have begun to be correlated with common sense among chatbots.&lt;/p&gt;

&lt;p&gt;When Geoffrey Nunberg [spoke about] in 1987 (https://www.aclweb.org/anthology/T87-1027/) in Position Paper on Common-sense and Formal Semantics, the concept of common sense began to be perceived at the level of esotericism and was avoided in every possible way. And now this common sense can even be touched and pampered with.&lt;/p&gt;

&lt;p&gt;Today I would like to share with you two types of knowledge that form the common sense of a chatbot.&lt;/p&gt;

&lt;p&gt;The first type of knowledge is semantic, it is built on the relationship “A is B”. The most popular resource is &lt;a href=&quot;http://conceptnet.io/&quot;&gt;ConceptNet&lt;/a&gt;, which began to form as early as 1999. As an illustration, a slide from &lt;a href=&quot;https://homes.cs.washington.edu/~msap/acl2020-commonsense/slides/03%20-%20Commonsense%20Resources.pdf&quot;&gt;Commonsense Tutorial (T6), Commonsense resources&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/conceptnet.jpg&quot; style=&quot;width: 50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Another type of knowledge is inferential knowledge, i.e. when we get new knowledge from the knowledge acquired earlier. The most popular resource is ATOMIC, which contains a set of facts about how X affects Y. I suggest playing with this model &lt;a href=&quot;https://mosaickg.apps.allenai.org/comet_atomic&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/atomic.png&quot; alt=&quot;Фрагмент карты взаимосвязей&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Thanks to the introduction of these models into chatbots, they are able to generate or select an answer that not only matches the topic of the conversation, but also fits into the set of facts voiced by the interlocutors. And below is an excellent example of such reasoning from the article by Svetlana Vakulenko&lt;a href=&quot;https://arxiv.org/abs/1806.06411&quot;&gt;Measuring Semantic Coherence of a Conversation&lt;/a&gt;. If you are not familiar with the Ubuntu operating system, the conversation may look like an incoherent set of phrases, but in fact the conversation is very consistent.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/ubuntu.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Both knowledge bases continue to grow, and the methods of their introduction into the dialogue with the chatbot are growing in quantity and quality. Who knows, maybe soon thinking sensibly about life with a chatbot will not be such a curiosity? Have you met people who are not entirely sane? What prompted you to give them such a title? Isn’t the general knowledge base the same?&lt;/p&gt;</content><author><name>Anna Liednikova</name></author><category term="post_en" /><category term="chatbot" /><summary type="html">It is pleasant to maintain a conversation with a person with common sense: he is able to think logically, has a basic set of facts about the world around him, and can connect them in a sequence. As a rule, we are not aware of all this and draw conclusions intuitively. But in order to teach a virtual friend common sense, you need to decompose the process into components. What are they in general terms?</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pasana.github.io/assets/img/posts/t6-slide1.jpg" /><media:content medium="image" url="https://pasana.github.io/assets/img/posts/t6-slide1.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">toxic chatbot</title><link href="https://pasana.github.io/chatbot/post_en/2020/11/14/toxic-chatbot.html" rel="alternate" type="text/html" title="toxic chatbot" /><published>2020-11-14T02:01:21+02:00</published><updated>2020-11-14T02:01:21+02:00</updated><id>https://pasana.github.io/chatbot/post_en/2020/11/14/toxic-chatbot</id><content type="html" xml:base="https://pasana.github.io/chatbot/post_en/2020/11/14/toxic-chatbot.html">&lt;p&gt;Technologies do not stand still, new models are emerging that can generate text. For chatbots, these models are trained on data from social networks such as Twitter or Reddit. But the better the text generation got, the more dangerous it became to use such chatbots. Why is that?&lt;/p&gt;

&lt;p&gt;A year ago, Microsoft released a new dialogue generation model trained on a huge data set - 147 million Reddit conversational threads from 2005 to 2017. The advantage of this model is that it can be easily adapted to suit your needs. But that’s bad luck! There are no links to sources in the article, just a small note: “Due to random toxic outputs, we cannot release the generation code at this time.” Now, it is already possible to indulge with this model &lt;a href=&quot;https://huggingface.co/microsoft/DialoGPT-large&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I myself have come across unpleasant responses from the GPT-2 model. Somehow in my practice there was such a dialogue:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Bot:&lt;/b&gt; Do you have difficulty with sleep?&lt;/li&gt;
&lt;li&gt;&lt;b&gt;User:&lt;/b&gt; Yes, sometimes I wake up in the middle of the night &lt;/li&gt;
&lt;li&gt;&lt;b&gt;Bot:&lt;/b&gt; What wakes you up? &lt;/li&gt;
&lt;li&gt;&lt;b&gt;User:&lt;/b&gt; Wife snoring&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Bot:&lt;/b&gt; So crush her with your pillow &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In general, after such an outcome, adjusting the model to the context and depriving it of creativity as much as possible, I smoothly moved away from generative models …&lt;/p&gt;

&lt;p&gt;You can also recall the robot &lt;a href=&quot;https://twitter.com/RealSophiaRobot&quot;&gt;Sophia&lt;/a&gt;, which at some point I was filled with hatred for humanity.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/sophia.png&quot; style=&quot;width: 50%; align: center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And where do the legs grow from? And from us, from dearest, they grow.&lt;/p&gt;

&lt;p&gt;3 years ago, in March 2018, the Conversation AI team, a research initiative founded by Jigsaw and Google, shared the Kaggle &lt;a href=&quot;https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge&quot;&gt;dataset&lt;/a&gt; with toxic comments so that users compete for the $ 35,000 prize and develop the best classifier.&lt;/p&gt;

&lt;p&gt;And this winter, 2020, it was already possible to test the application &lt;a href=&quot;https://detoxifai.com/&quot;&gt;detoxifAI&lt;/a&gt;, which simply hides stinging and violent comments on the Internet.&lt;/p&gt;

&lt;p&gt;Let’s get back to chatbots. How to deal with them? After all, generative models make the conversation interesting and unpredictable. Six months after Microsoft, Facebook released the Blender model, which is particularly friendly and positive. However, in their article, they warn that since the model was originally trained on Reddit, the likelihood of toxicity still remains.&lt;/p&gt;

&lt;p&gt;They managed to achieve a significant improvement with a very simple solution: the candidates proposed by the model for responding to the interlocutor are filtered by a classifier similar to those developed on Kaggle.&lt;/p&gt;

&lt;p&gt;Here we are! I hope you are not involved in these riots and very pleasant interlocutors. In the meantime, you can bet, what will happen first: will people learn to filter their talk on the Internet, or will technology find a way to instantly neutralize them?&lt;/p&gt;</content><author><name>Anna Liednikova</name></author><category term="post_en" /><category term="chatbot" /><summary type="html">Technologies do not stand still, new models are emerging that can generate text. For chatbots, these models are trained on data from social networks such as Twitter or Reddit. But the better the text generation got, the more dangerous it became to use such chatbots. Why is that?</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pasana.github.io/assets/img/posts/sophia.png" /><media:content medium="image" url="https://pasana.github.io/assets/img/posts/sophia.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">токсичные чатботы</title><link href="https://pasana.github.io/%D1%87%D0%B0%D1%82%D0%B1%D0%BE%D1%82/post_ru/2020/11/14/toksichnye-chatboty.html" rel="alternate" type="text/html" title="токсичные чатботы" /><published>2020-11-14T02:01:21+02:00</published><updated>2020-11-14T02:01:21+02:00</updated><id>https://pasana.github.io/%D1%87%D0%B0%D1%82%D0%B1%D0%BE%D1%82/post_ru/2020/11/14/toksichnye-chatboty</id><content type="html" xml:base="https://pasana.github.io/%D1%87%D0%B0%D1%82%D0%B1%D0%BE%D1%82/post_ru/2020/11/14/toksichnye-chatboty.html">&lt;p&gt;Технологии не стоят на месте, появляются новые модели способные генерировать текст. Для чатботов такие модели тренируются на данных социальных сетей, например, Twitter или Reddit. Но чем лучше становилась генерация текста, тем опаснее становилось использование таких чатботов. Почему же?&lt;/p&gt;

&lt;p&gt;Год назад Microsoft выпустила новую модель генерации диалога, обученную на огромном массиве данных - 147 миллионов разговорных веток Reddit c 2005 по 2017 год. Преимущество данной модели, что ее легко можно адаптировать под свои нужды. Но вот незадача! Ссылки на источники в статье нет, только небольшая пометка: “Из-за случайных токсичных выходов мы не можем выпустить код генерации в настоящее время.” Сейчас же с этой моделью уже можно баловаться &lt;a href=&quot;https://huggingface.co/microsoft/DialoGPT-large&quot;&gt;тут&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Мне и самой приходилось встречаться с неприятными ответами модели GPT-2. Как-то на моей практике был такой диалог:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Бот:&lt;/b&gt; Испытываете ли вы трудности со сном?&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Пользователь:&lt;/b&gt; Да, иногда просыпаюсь ночью&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Бот:&lt;/b&gt; Что вас будит ночью?&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Пользователь:&lt;/b&gt; Жена храпит&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Бот:&lt;/b&gt; Так задави ее подушкой&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;В общем, после такого исхода, подогнав модель под контекст и максимально лишив ее творчества, я плавно отошла от генеративных моделей…&lt;/p&gt;

&lt;p&gt;Тут же можно вспомнить робота &lt;a href=&quot;https://twitter.com/RealSophiaRobot&quot;&gt;Софию&lt;/a&gt;, которая в какой-то момент прониклась ненавистью к человечеству.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/sophia.png&quot; style=&quot;width: 50%; align: center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;А откуда ноги то растут? А от нас, от родненьких, и растут.&lt;/p&gt;

&lt;p&gt;3 года назад, в марте 2018 года, команда Conversation AI, исследовательская инициатива, основанная Jigsaw и Google поделились на Kaggle &lt;a href=&quot;https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge&quot;&gt;датасетом&lt;/a&gt; с токсичными комментариями, чтобы пользователи поборолись за приз $35000 и разработали наилучший классификатор.&lt;/p&gt;

&lt;p&gt;А этой зимой, 2020 года, можно было уже протестировать приложение &lt;a href=&quot;https://detoxifai.com/&quot;&gt;detoxifAI&lt;/a&gt;, которое просто напросто скрывает язвительные и жестокие комментарии в интернете.&lt;/p&gt;

&lt;p&gt;Давайте вернемся к чатботам. Как же с ними быть? Ведь генеративные модели делают разговор интересным и мало предсказуемым. Спустя полгода после Microsoft, Facebook выпустил модель Blender, который отличается особым дружелюбием и позитивом. Тем не менее в своей статье они предупреждают, что поскольку изначально модель тренировалась на Reddit, вероятность токсичности все еще остается.&lt;/p&gt;

&lt;p&gt;Добиться значительного улучшения им удалось весьма простым решением: предлагаемые моделью кандидаты для ответа собеседнику фильтруются классификатором, подобным тем, что разрабатывали на Kaggle.&lt;/p&gt;

&lt;p&gt;Такие дела, дорогие мои! Надеюсь, вы не причастны к этим беспорядкам и весьма приятные собеседники. А пока можно делать ставки, что произойдет раньше: люди научаться “фильтровать свой базар” в интернете или технологии найдут способ их моментально обезвреживать?&lt;/p&gt;</content><author><name>Anna Liednikova</name></author><category term="post_ru" /><category term="чатбот" /><summary type="html">Технологии не стоят на месте, появляются новые модели способные генерировать текст. Для чатботов такие модели тренируются на данных социальных сетей, например, Twitter или Reddit. Но чем лучше становилась генерация текста, тем опаснее становилось использование таких чатботов. Почему же?</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pasana.github.io/assets/img/posts/sophia.png" /><media:content medium="image" url="https://pasana.github.io/assets/img/posts/sophia.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">здравый смысл у чатбота</title><link href="https://pasana.github.io/%D1%87%D0%B0%D1%82%D0%B1%D0%BE%D1%82/post_ru/2020/11/14/zdravyj-smysl-u-chatbota.html" rel="alternate" type="text/html" title="здравый смысл у чатбота" /><published>2020-11-14T02:01:21+02:00</published><updated>2020-11-14T02:01:21+02:00</updated><id>https://pasana.github.io/%D1%87%D0%B0%D1%82%D0%B1%D0%BE%D1%82/post_ru/2020/11/14/zdravyj-smysl-u-chatbota</id><content type="html" xml:base="https://pasana.github.io/%D1%87%D0%B0%D1%82%D0%B1%D0%BE%D1%82/post_ru/2020/11/14/zdravyj-smysl-u-chatbota.html">&lt;p&gt;Приятно поддерживать беседу с собеседником со здравым смыслом: он способен логично мыслить, имеет базовый набор фактов об окружающем мире, может связывать их в последовательность. Как правило, мы всего этого не осознаем и делаем выводы интуитивно. Но, чтобы научить виртуального друга здравому смыслу, нужно разложить процесс на компоненты. Какие же они в общих чертах?&lt;/p&gt;

&lt;p&gt;Большинство сегодняшних чатботов являются семантичными. Я не беру в расчет тех, кто построен на детерминированных правилах. “Ход мыслей” семантического чатбота можно соотнести с нашим интуитивным мышлением, построенном на ассоциациях.&lt;/p&gt;

&lt;p&gt;Способность к рассуждению - это навык более энергоемкий и включает в себя построение не столько ассоциативных связей, сколько причинно-следственных.&lt;/p&gt;

&lt;p&gt;В качестве примера приведу слайд из &lt;a href=&quot;https://homes.cs.washington.edu/~msap/acl2020-commonsense/slides/03%20-%20Commonsense%20Resources.pdf&quot;&gt;Commonsense Tutorial (T6), Commonsense resources&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/t6-slide1.jpg&quot; style=&quot;width: 50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Для того, чтобы быть способным строить эти причинно-следственные связи, необходим какой-то базовый набор фактов, своего рода аксиом, об окружающей среде.&lt;/p&gt;

&lt;p&gt;И вот тут мы плавно подошли к понятию базы знаний и размышлений. Но лишь недавно их стали соотносить со здравым смыслом у чатботов.&lt;/p&gt;

&lt;p&gt;Когда об этом в 1987 году &lt;a href=&quot;https://www.aclweb.org/anthology/T87-1027/&quot;&gt;заговорил&lt;/a&gt; Geoffrey Nunberg в Position Paper on Common-sense and Formal Semantics, то понятие здравого смысла (common sense) стало восприниматься на уровне эзотерики и его всячески избегали. А сейчас этот здравый смысл можно даже пощупать и побаловаться с ним.&lt;/p&gt;

&lt;p&gt;Сегодня я бы хотела с вами поделиться двумя типами знаний, которые формируют здравый смысл чатбота.&lt;/p&gt;

&lt;p&gt;Первый тип знаний - это семантический, он построен на взаимосвязях “А является Б”. Наиболее популярный ресурс - это &lt;a href=&quot;http://conceptnet.io/&quot;&gt;ConceptNet&lt;/a&gt;, который начали формировать аж в 1999 году. В качестве иллюстрации - слайд из &lt;a href=&quot;https://homes.cs.washington.edu/~msap/acl2020-commonsense/slides/03%20-%20Commonsense%20Resources.pdf&quot;&gt;Commonsense Tutorial (T6), Commonsense resources&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/conceptnet.jpg&quot; style=&quot;width: 50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Другой тип знаний - это выводное знание, т.е. когда мы получаем новые знания из знаний приобретенных ранее . Наиболее популярных ресурс - это ATOMIC, который содержить в себе набор фактов, как X влияет на Y. Предлагаю побаловаться с данной моделью &lt;a href=&quot;https://mosaickg.apps.allenai.org/comet_atomic&quot;&gt;тут&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/atomic.png&quot; alt=&quot;Фрагмент карты взаимосвязей&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Благодаря внедрению этих моделей в чатботов, они в состоянии генерировать или выбирать ответ, который не только отвечает тематике разговора, но и вписывается в набор фактов, озвученных собеседниками. А ниже отличный пример такого рассуждения из статьи Светланы Вакуленко &lt;a href=&quot;https://arxiv.org/abs/1806.06411&quot;&gt;Measuring Semantic Coherence of a Conversation&lt;/a&gt;. Если не быть знакомым с операционной системой Ubuntu, то выглядит разговор может выглядеть как несвязных набор фраз, но на самом деле разговор весьма последовательный.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/ubuntu.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Обе базы знаний продолжают пополняться, а методы их внедрения в диалог с чатботом растут в количестве и качестве. Кто знает, возможно скоро здраво порассуждать о жизни с чатботом будет не такой уж и диковинкой? А встречались ли вам люди не совсем здравомыслящие? Что же побуждало вас вручить им такой титул? Не та же ли общая база знаний?&lt;/p&gt;</content><author><name>Anna Liednikova</name></author><category term="post_ru" /><category term="чатбот" /><summary type="html">Приятно поддерживать беседу с собеседником со здравым смыслом: он способен логично мыслить, имеет базовый набор фактов об окружающем мире, может связывать их в последовательность. Как правило, мы всего этого не осознаем и делаем выводы интуитивно. Но, чтобы научить виртуального друга здравому смыслу, нужно разложить процесс на компоненты. Какие же они в общих чертах?</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pasana.github.io/assets/img/posts/t6-slide1.jpg" /><media:content medium="image" url="https://pasana.github.io/assets/img/posts/t6-slide1.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">chatbot and empathy</title><link href="https://pasana.github.io/chatbot/post_en/2020/11/12/chatbot-and-empathy.html" rel="alternate" type="text/html" title="chatbot and empathy" /><published>2020-11-12T02:01:21+02:00</published><updated>2020-11-12T02:01:21+02:00</updated><id>https://pasana.github.io/chatbot/post_en/2020/11/12/chatbot-and-empathy</id><content type="html" xml:base="https://pasana.github.io/chatbot/post_en/2020/11/12/chatbot-and-empathy.html">&lt;p&gt;Recently, the topic of emotional intelligence has become popular and the issue of the importance of empathy has been raised. On almost any social network, help could be found on how to identify emotions and express support for the interlocutor. But do you think that only people learn this? Chatbots too!&lt;/p&gt;

&lt;p&gt;It is believed that the first emotional chatbot was &lt;a href=&quot;https://www.botlibre.com/bot.&quot;&gt;PARRY&lt;/a&gt;, Which tried to simulate a paranoid schizophrenic.&lt;/p&gt;

&lt;p&gt;Then in 2014, the Chinese launched XiaoIce. If suddenly you can speak Mandarin, then you can chat &lt;a href=&quot;https://www.msxiaobing.com/&quot;&gt;here&lt;/a&gt;. Well, they launched it and the popularity is growing, the business is expanding.&lt;/p&gt;

&lt;p&gt;5 years later, in 2019, when the popularity of social and empathic chatbots began to grow and there were more competitors, the authors of XiaoIce decided not to stand aside and finally publish &lt;a href=&quot;https://arxiv.org/pdf/1812.08989 .pdf&quot;&gt;details of their product&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;What actually caused this popularity?&lt;/p&gt;

&lt;p&gt;In 2018, Hao Zhou and his partners published an &lt;a href=&quot;https://arxiv.org/abs/1704.01074&quot;&gt;article&lt;/a&gt;, in which he modestly noted that here we are generating everything and generating text, but why does no one think about emotions? Indeed, one and the same phrase can be answered in very different ways, depending on our reactions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/emotion-transfer.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And then it started! It has already been quoted 332 times by the developers of “emotional talkers”. Even the giants have pulled up.&lt;/p&gt;

&lt;p&gt;Just six months later, Facebook published a new dataset Empathetic Dialogues with 25,000 dialogs with 19 emotions! So try not to pry and name all 19? Although it is worth looking at the plate below and nothing supernatural: all these emotions are really familiar to us.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/emotions.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Such a large amount of data and markup allowed chatbots to take another step forward: now they not only change their text to suit the emotion, but also choose the correct response to the emotion of the interlocutor.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/empadialogs.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A couple of months later, Zhaojiang Lin and the company decided to quickly train their chatbot CAiRE, which you can chat with here at &lt;a href=&quot;http://eez115.ece.ust.hk:8899/&quot;&gt;this link&lt;/a&gt;. The problem is that the dataset and models are not perfect and there are still situations in which the chatbot does not give the correct answer. So why not let users fix it? And in real life, by the way, this can lead to a conflict.&lt;/p&gt;

&lt;p&gt;This dataset is now used in many chatbots, including Facebook’s latest open source state-of-the-art &lt;a href=&quot;https://venturebeat.com/2020/04/29/facebook-open-sources-blender-a-chatbot-that-people-say-feels-more-human/&quot;&gt;Blender&lt;/a&gt;. But about him some other time.&lt;/p&gt;

&lt;p&gt;This is how chatbots learned to be emotional and empathic! Do you study too? Or maybe you already know how? What emotions are you meeting? Will you define all 19? And how much does your speech change when the emotion is out of sync with the situation?&lt;/p&gt;</content><author><name>Anna Liednikova</name></author><category term="post_en" /><category term="chatbot" /><summary type="html">Recently, the topic of emotional intelligence has become popular and the issue of the importance of empathy has been raised. On almost any social network, help could be found on how to identify emotions and express support for the interlocutor. But do you think that only people learn this? Chatbots too!</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pasana.github.io/assets/img/posts/emotion-transfer.png" /><media:content medium="image" url="https://pasana.github.io/assets/img/posts/emotion-transfer.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>